{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "# 让这份笔记同步支持 python 2 和 python 3\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用statsmodels便于统计分析数据\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "#使用sklearn便于预测（机器学习）\n",
    "from sklearn import linear_model\n",
    "#使用patsy便于生成模型\n",
    "import patsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 Lab: Cross-Validation and the Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.1 The Validation Set Approach**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0    70   \n",
       "1  15.0          8         350.0       165.0    3693          11.5    70   \n",
       "2  18.0          8         318.0       150.0    3436          11.0    70   \n",
       "3  16.0          8         304.0       150.0    3433          12.0    70   \n",
       "4  17.0          8         302.0       140.0    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Auto = pd.read_csv('Data/Auto.csv', na_values='?').dropna()\n",
    "Auto.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> library(ISLR)\n",
    "\n",
    "> set.seed(1)\n",
    "\n",
    "> train=sample (392,196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(Auto, test_size = 0.5, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#> lm.fit=lm(mpg∼horsepower ,data=Auto,subset=train)\n",
    "y_train,X_train = patsy.dmatrices('mpg ~ 0 + horsepower',data = train_set,return_type=\"dataframe\")\n",
    "y_test,X_test = patsy.dmatrices('mpg ~ 0 + horsepower',data = test_set,return_type=\"dataframe\")\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> attach(Auto)\n",
    "\n",
    "> mean((mpg -predict(lm.fit ,Auto))[-train]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg    24.802121\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((y_test - lin_reg.predict(X_test))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.80212062059356"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_test,lin_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> lm.fit2=lm(mpg∼poly(horsepower ,2),data=Auto,subset=train)\n",
    "\n",
    "> mean((mpg -predict(lm.fit2,Auto))[-train]^2)\n",
    "\n",
    "> lm.fit3=lm(mpg∼poly(horsepower ,3),data=Auto,subset=train)\n",
    "\n",
    "> mean((mpg -predict(lm.fit3,Auto))[-train]^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.848292603275663"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree = 2,include_bias=False)\n",
    "X_train_degree = poly_features.fit_transform(X_train)\n",
    "X_test_degree =  poly_features.fit_transform(X_test)\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train_degree,y_train)\n",
    "mean_squared_error(y_test,lin_reg.predict(X_test_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.805111358604705"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree = 3,include_bias=False)\n",
    "X_train_degree = poly_features.fit_transform(X_train)\n",
    "X_test_degree =  poly_features.fit_transform(X_test)\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train_degree,y_train)\n",
    "mean_squared_error(y_test,lin_reg.predict(X_test_degree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> set.seed(2)\n",
    "\n",
    "> train=sample (392,196)\n",
    "\n",
    "> lm.fit=lm(mpg∼horsepower ,subset=train)\n",
    "\n",
    "> mean((mpg -predict(lm.fit ,Auto))[-train]^2)\n",
    "\n",
    "> lm.fit2=lm(mpg∼poly(horsepower ,2),data=Auto,subset=train)\n",
    "\n",
    "> mean((mpg -predict(lm.fit2,Auto))[-train]^2)\n",
    "\n",
    "> lm.fit3=lm(mpg∼poly(horsepower ,3),data=Auto,subset=train)\n",
    "\n",
    "> mean((mpg -predict(lm.fit3,Auto))[-train]^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.442643969985735"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(Auto, test_size = 0.5, random_state = 2)\n",
    "y_train,X_train = patsy.dmatrices('mpg ~ 0 + horsepower',data = train_set,return_type=\"dataframe\")\n",
    "y_test,X_test = patsy.dmatrices('mpg ~ 0 + horsepower',data = test_set,return_type=\"dataframe\")\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "mean_squared_error(y_test,lin_reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.550198801910312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree = 2,include_bias=False)\n",
    "X_train_degree = poly_features.fit_transform(X_train)\n",
    "X_test_degree =  poly_features.fit_transform(X_test)\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train_degree,y_train)\n",
    "mean_squared_error(y_test,lin_reg.predict(X_test_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.59522229455435"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_features = PolynomialFeatures(degree = 3,include_bias=False)\n",
    "X_train_degree = poly_features.fit_transform(X_train)\n",
    "X_test_degree =  poly_features.fit_transform(X_test)\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "lin_reg.fit(X_train_degree,y_train)\n",
    "mean_squared_error(y_test,lin_reg.predict(X_test_degree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用statsmodels方案再次实现，为了和5.1.2的glm做个比较**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.80212062059357"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(Auto, test_size = 0.5, random_state = 1)\n",
    "lm_fit = smf.ols('mpg ~ horsepower',train_set).fit()\n",
    "((test_set['mpg'] - lm_fit.predict(test_set['horsepower']))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.848292603274604"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit = smf.ols('mpg ~ horsepower + I(horsepower ** 2)',train_set).fit()\n",
    "((test_set['mpg'] - lm_fit.predict(test_set['horsepower']))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.805111358430317"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit = smf.ols('mpg ~ horsepower + I(horsepower ** 2) + I(horsepower ** 3)',train_set).fit()\n",
    "((test_set['mpg'] - lm_fit.predict(test_set['horsepower']))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.442643969985753"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(Auto, test_size = 0.5, random_state = 2)\n",
    "lm_fit = smf.ols('mpg ~ horsepower',train_set).fit()\n",
    "((test_set['mpg'] - lm_fit.predict(test_set['horsepower']))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.550198801910696"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit = smf.ols('mpg ~ horsepower + I(horsepower ** 2)',train_set).fit()\n",
    "((test_set['mpg'] - lm_fit.predict(test_set['horsepower']))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.595222294405293"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit = smf.ols('mpg ~ horsepower + I(horsepower ** 2) + I(horsepower ** 3)',train_set).fit()\n",
    "((test_set['mpg'] - lm_fit.predict(test_set['horsepower']))**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.2 Leave-One-Out Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> glm.fit=glm(mpg∼horsepower ,data=Auto)\n",
    "\n",
    "> coef(glm.fit)\n",
    "\n",
    "> lm.fit=lm(mpg∼horsepower ,data=Auto)\n",
    "\n",
    "> coef(lm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit = smf.glm('mpg ~ horsepower',Auto).fit()\n",
    "lm_fit.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_fit = smf.ols('mpg ~ horsepower',Auto).fit()\n",
    "lm_fit.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> library(boot)\n",
    "\n",
    "> glm.fit=glm(mpg∼horsepower ,data=Auto)\n",
    "\n",
    "> cv.err=cv.glm(Auto ,glm.fit)\n",
    "\n",
    "> cv.err$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.231513517929226"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "y_mpg,X_horsepower_float = patsy.dmatrices('mpg ~ 0 + horsepower',data = Auto,return_type=\"dataframe\")\n",
    "-cross_val_score(lin_reg, X_horsepower_float, y_mpg, cv = len(y_mpg), scoring='neg_mean_squared_error').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> cv.error=rep(0,5)\n",
    "\n",
    "> for (i in 1:5){\n",
    "+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)\n",
    "+ cv.error[i]=cv.glm(Auto,glm.fit)$delta[1]\n",
    "+ }\n",
    "\n",
    "> cv.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.23\n",
      "19.25\n",
      "19.33\n",
      "19.42\n",
      "19.03\n"
     ]
    }
   ],
   "source": [
    "def msr_of_polynomial_cv(data,model,degree = 1,cv = 10,groups = None):\n",
    "    lin_reg = linear_model.LinearRegression()\n",
    "    y,X = patsy.dmatrices(model,data = data,return_type=\"dataframe\")\n",
    "    poly_features = PolynomialFeatures(degree = degree,include_bias=False)\n",
    "    X_degree = poly_features.fit_transform(X)\n",
    "    msr = -cross_val_score(lin_reg, X_degree, y, cv = cv, scoring='neg_mean_squared_error',groups = groups)\n",
    "    return msr\n",
    "for i in range(5):\n",
    "    print((msr_of_polynomial_cv(Auto,'mpg ~ 0 + horsepower',degree = i + 1,cv = len(y_mpg))).mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.3 k-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> set.seed(17)\n",
    "\n",
    "> cv.error.10=rep(0,10)\n",
    "\n",
    "> for (i in 1:10){\n",
    "+ glm.fit=glm(mpg∼poly(horsepower ,i),data=Auto)\n",
    "+ cv.error.10[i]=cv.glm(Auto,glm.fit,K=10)$delta[1]\n",
    "+ }\n",
    "\n",
    "> cv.error.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.44\n",
      "21.24\n",
      "21.34\n",
      "21.35\n",
      "20.91\n",
      "20.78\n",
      "20.99\n",
      "21.08\n",
      "21.04\n",
      "20.98\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(17)\n",
    "#shuffled_indices = np.random.permutation(len(Auto))\n",
    "for i in range(10):\n",
    "    #print((msr_of_polynomial_cv(Auto.iloc[shuffled_indices],'mpg ~ horsepower',degree = i + 1,cv = 10)).mean().round(2))\n",
    "    print((msr_of_polynomial_cv(Auto,'mpg ~ 0 + horsepower',degree = i + 1,cv = 10)).mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3.4 The Bootstrap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.895251</td>\n",
       "      <td>-0.234924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.562454</td>\n",
       "      <td>-0.885176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.417090</td>\n",
       "      <td>0.271888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.044356</td>\n",
       "      <td>-0.734198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.315568</td>\n",
       "      <td>0.841983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y\n",
       "0 -0.895251 -0.234924\n",
       "1 -1.562454 -0.885176\n",
       "2 -0.417090  0.271888\n",
       "3  1.044356 -0.734198\n",
       "4 -0.315568  0.841983"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Portfolio = pd.read_csv(\"data/Portfolio.csv\")\n",
    "Portfolio.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> alpha.fn=function (data,index){\n",
    "+ X=data$X[index]\n",
    "+ Y=data$Y[index]\n",
    "+ return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))\n",
    "+ }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据自助法数据 α估计生成标准误差\n",
    "def alpha_fn(data, index_start = 0,index_end = None):\n",
    "    if index_end == None:\n",
    "        index_end = len(data)\n",
    "    X = data['X'].iloc[index_start:index_end]\n",
    "    Y = data['Y'].iloc[index_start:index_end]\n",
    "    return (np.var(Y) - np.cov(X,Y)[0,1])/(np.var(X) + np.var(Y) - 2* np.cov(X,Y)[0,1])\n",
    "    #对于pd数据，可以使用return (Y.var() - X.cov(Y))/(X.var() + Y.var() - 2* X.cov(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5766511516104116"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#> alpha.fn(Portfolio ,1:100)\n",
    "alpha_fn(Portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> set.seed(1)\n",
    "\n",
    "> alpha.fn(Portfolio ,sample (100,100, replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4504820492455901"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_fn(Portfolio.sample(100,replace=True,random_state= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     original      mean      bias  std. error\n",
      "t0*  0.576651  0.574853  0.001798    0.092798\n"
     ]
    }
   ],
   "source": [
    "#> boot(Portfolio ,alpha.fn,R=1000)定义对data根据statistic统计方式采样R次的生成数据，详见实验\n",
    "def bootstrap_stats(data, statistic, R):\n",
    "    n_shape = len(data)\n",
    "    try:\n",
    "        statistic_original = list(statistic(data))\n",
    "    except TypeError:\n",
    "        statistic_original = [statistic(data)]\n",
    "    statistic_list = []\n",
    "    train_list = []\n",
    "    statistic_len = len(statistic_original)\n",
    "    for statistic_t in range(statistic_len):\n",
    "        statistic_list.append([])\n",
    "    for random_state in range(R):\n",
    "        train = data.sample(n = n_shape,replace=True,random_state= random_state)\n",
    "        try:\n",
    "            float(statistic(train))\n",
    "        except:\n",
    "            try: \n",
    "                for statistic_factor in list(statistic(train)):\n",
    "                    float(statistic_factor)\n",
    "            except:\n",
    "                continue\n",
    "        train_list.append(train)\n",
    "        for statistic_t in range(statistic_len):\n",
    "            try:\n",
    "                statistic_list[statistic_t].append(list(statistic(train))[statistic_t])\n",
    "            except TypeError:\n",
    "                statistic_list[statistic_t].append([statistic(train)][statistic_t])\n",
    "    statistic_index = []\n",
    "    statistic_mean = []\n",
    "    statistic_std_error = []\n",
    "    statistic_bias = []\n",
    "    for statistic_t in range(statistic_len):\n",
    "        statistic_index.append('t' + str(statistic_t) + '*')\n",
    "        statistic_mean.append(np.mean(statistic_list[statistic_t]))\n",
    "        statistic_std_error.append(((np.sum((statistic_list[statistic_t] - statistic_mean[statistic_t]) ** 2)) / (R - 1)) ** 0.5)\n",
    "        statistic_bias.append(statistic_original[statistic_t] - statistic_mean[statistic_t])\n",
    "    bootstrap_stats_pd = pd.DataFrame({'original':statistic_original,\n",
    "                                       'mean':statistic_mean,\n",
    "                                       'bias':statistic_bias,\n",
    "                                       'std. error':statistic_std_error                                      \n",
    "                                      },\n",
    "                                     index = statistic_index)\n",
    "    print(bootstrap_stats_pd)\n",
    "    return statistic_list\n",
    "statistic_list = bootstrap_stats(Portfolio ,alpha_fn, R=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> boot.fn=function (data ,index)\n",
    "+ return(coef(lm(mpg∼horsepower ,data=data,subset=index)))\n",
    "\n",
    "> boot.fn(Auto ,1:392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.935861\n",
       "horsepower    -0.157845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def boot_fn(data):\n",
    "    return(smf.ols('mpg ~ horsepower',data).fit().params)\n",
    "boot_fn(Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> set.seed(1)\n",
    "\n",
    "> boot.fn(Auto ,sample (392,392, replace=T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.658479\n",
       "horsepower    -0.155898\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_fn(Auto.sample(392,replace=True,random_state= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept     39.101022\n",
       "horsepower    -0.151630\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_fn(Auto.sample(392,replace=True,random_state= 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      original       mean      bias  std. error\n",
      "t0*  39.935861  39.952723 -0.016862    0.862084\n",
      "t1*  -0.157845  -0.158133  0.000288    0.007416\n"
     ]
    }
   ],
   "source": [
    "#> boot(Auto ,boot.fn,1000)\n",
    "statistic_list = bootstrap_stats(Auto, boot_fn, R=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   599.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>7.03e-81</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:32:33</td>     <th>  Log-Likelihood:    </th> <td> -1178.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2361.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   390</td>      <th>  BIC:               </th> <td>   2369.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   39.9359</td> <td>    0.717</td> <td>   55.660</td> <td> 0.000</td> <td>   38.525</td> <td>   41.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th> <td>   -0.1578</td> <td>    0.006</td> <td>  -24.489</td> <td> 0.000</td> <td>   -0.171</td> <td>   -0.145</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.432</td> <th>  Durbin-Watson:     </th> <td>   0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  17.305</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.492</td> <th>  Prob(JB):          </th> <td>0.000175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.299</td> <th>  Cond. No.          </th> <td>    322.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.606\n",
       "Model:                            OLS   Adj. R-squared:                  0.605\n",
       "Method:                 Least Squares   F-statistic:                     599.7\n",
       "Date:                Sun, 29 Dec 2019   Prob (F-statistic):           7.03e-81\n",
       "Time:                        22:32:33   Log-Likelihood:                -1178.7\n",
       "No. Observations:                 392   AIC:                             2361.\n",
       "Df Residuals:                     390   BIC:                             2369.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     39.9359      0.717     55.660      0.000      38.525      41.347\n",
       "horsepower    -0.1578      0.006    -24.489      0.000      -0.171      -0.145\n",
       "==============================================================================\n",
       "Omnibus:                       16.432   Durbin-Watson:                   0.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.305\n",
       "Skew:                           0.492   Prob(JB):                     0.000175\n",
       "Kurtosis:                       3.299   Cond. No.                         322.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#> summary(lm(mpg∼horsepower ,data=Auto))$coef\n",
    "smf.ols('mpg ~ horsepower',Auto).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> boot.fn=function (data ,index)\n",
    "+ coefficients(lm(mpg∼horsepower +I(horsepower ^2),data=data ,\n",
    "subset=index))\n",
    "\n",
    "> set.seed(1)\n",
    "\n",
    "> boot(Auto ,boot.fn,1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      original       mean      bias  std. error\n",
      "t0*  56.900100  56.934265 -0.034165    2.082847\n",
      "t1*  -0.466190  -0.467016  0.000827    0.033048\n",
      "t2*   0.001231   0.001234 -0.000004    0.000119\n"
     ]
    }
   ],
   "source": [
    "def boot_fn(data):\n",
    "    return(smf.ols('mpg ~ horsepower + I( horsepower ** 2)',data).fit().params)\n",
    "statistic_list = bootstrap_stats(Auto, boot_fn, R=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>mpg</td>       <th>  R-squared:         </th> <td>   0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   428.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Dec 2019</td> <th>  Prob (F-statistic):</th> <td>5.40e-99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:33:41</td>     <th>  Log-Likelihood:    </th> <td> -1133.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   392</td>      <th>  AIC:               </th> <td>   2272.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   389</td>      <th>  BIC:               </th> <td>   2284.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>   56.9001</td> <td>    1.800</td> <td>   31.604</td> <td> 0.000</td> <td>   53.360</td> <td>   60.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>horsepower</th>         <td>   -0.4662</td> <td>    0.031</td> <td>  -14.978</td> <td> 0.000</td> <td>   -0.527</td> <td>   -0.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(horsepower ** 2)</th> <td>    0.0012</td> <td>    0.000</td> <td>   10.080</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.158</td> <th>  Durbin-Watson:     </th> <td>   1.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  30.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.218</td> <th>  Prob(JB):          </th> <td>2.20e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.299</td> <th>  Cond. No.          </th> <td>1.29e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.29e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    mpg   R-squared:                       0.688\n",
       "Model:                            OLS   Adj. R-squared:                  0.686\n",
       "Method:                 Least Squares   F-statistic:                     428.0\n",
       "Date:                Sun, 29 Dec 2019   Prob (F-statistic):           5.40e-99\n",
       "Time:                        22:33:41   Log-Likelihood:                -1133.2\n",
       "No. Observations:                 392   AIC:                             2272.\n",
       "Df Residuals:                     389   BIC:                             2284.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept             56.9001      1.800     31.604      0.000      53.360      60.440\n",
       "horsepower            -0.4662      0.031    -14.978      0.000      -0.527      -0.405\n",
       "I(horsepower ** 2)     0.0012      0.000     10.080      0.000       0.001       0.001\n",
       "==============================================================================\n",
       "Omnibus:                       16.158   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               30.662\n",
       "Skew:                           0.218   Prob(JB):                     2.20e-07\n",
       "Kurtosis:                       4.299   Cond. No.                     1.29e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.29e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary(lm(mpg∼horsepower +I(horsepower ^2),data=Auto))$coef\n",
    "smf.ols('mpg ~ horsepower + I( horsepower ** 2)',Auto).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
